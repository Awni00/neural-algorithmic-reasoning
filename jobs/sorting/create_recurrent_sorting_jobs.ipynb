{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from dotenv import load_dotenv\n",
    "import copy\n",
    "import yaml\n",
    "\n",
    "import os, sys; sys.path.insert(0, os.path.abspath('../..')) # add project root dir to path\n",
    "from experiments.sorting.recurrent_model import get_experiment_name\n",
    "from utils.utils import AttributeDict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def mkdir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global job parameters\n",
    "\n",
    "job_directory = f\"job_scripts\"\n",
    "out_dir = f'.out'\n",
    "time_str = '00-4:00:00'\n",
    "partition = 'gpu'\n",
    "ntasks = 1\n",
    "nodes = 1\n",
    "cpu_per_gpu = 8\n",
    "mem_per_cpu = 64\n",
    "n_gpus = 1\n",
    "\n",
    "cluster = 'misha'\n",
    "\n",
    "if cluster == 'grace':\n",
    "    gpus_constraints = '\"a100|rtx3090|v100|rtx2080ti\"' # for grace\n",
    "# gpus_constraints = \"a40\" #'\"h100|a100\"' # for misha\n",
    "\n",
    "netid = os.getenv('NETID')\n",
    "project_dir = f\"/home/{netid}/project/neural-algorithmic-reasoning/experiments/sorting\"\n",
    "\n",
    "mkdir(job_directory)\n",
    "mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base model, train, and data config\n",
    "import yaml\n",
    "base_config_dir = f'{project_dir}/experiment_configs/base_config_recurrent'\n",
    "\n",
    "with open(os.path.join(base_config_dir, 'model_config.yaml')) as f:\n",
    "    base_model_config = AttributeDict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "\n",
    "with open(os.path.join(base_config_dir, 'train_config.yaml')) as f:\n",
    "    base_train_config = AttributeDict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "\n",
    "with open(os.path.join(base_config_dir, 'data_config.yaml')) as f:\n",
    "    base_data_config = AttributeDict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "\n",
    "config_out_dir = f'{project_dir}/experiment_configs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 192 jobs\n"
     ]
    }
   ],
   "source": [
    "n_layers = [2] # [2, 4]\n",
    "d_model = [256]\n",
    "dff_expansion = [2]\n",
    "\n",
    "\n",
    "# TODO: add variation over MLP activation functions, e.g. softmax linear unit, etc.\n",
    "# search over dff_expansion, or other MLP params\n",
    "\n",
    "random_train_length = [True, False]\n",
    "pos_enc_type = ['sinusoidal', 'rotary', 't5', 'alibi']\n",
    "input_recall = [True, False]\n",
    "attn_score_fn = ['softmax'] # , 'topk-softmax', 'hard', 'sigmoid']\n",
    "discrete_intermediate_map = ['solu', 'softmax', 'topk-softmax', 'hard', 'gumbel-softmax'] # None,'sigmoid', 'relu'\n",
    "progressive_training = [True, False]\n",
    "incremental_training = [True, False]\n",
    "weight_tying = [False] # [True, False]\n",
    "\n",
    "jobs_overwrite_params = []\n",
    "for L, D, F, posenc, ir, attn_fn, disc_map, progtr, inctr, randlen in itertools.product(\n",
    "    n_layers, d_model, dff_expansion, pos_enc_type, input_recall, attn_score_fn, discrete_intermediate_map, progressive_training, incremental_training, random_train_length):\n",
    "\n",
    "    # copy base configs\n",
    "    job_model_config = copy.deepcopy(base_model_config)\n",
    "    job_train_config = copy.deepcopy(base_train_config)\n",
    "    job_data_config = copy.deepcopy(base_data_config)\n",
    "\n",
    "    ### update model config\n",
    "\n",
    "    # attn_kwargs params\n",
    "    attn_kwargs = dict(attn_score_fn=attn_fn)\n",
    "    if attn_fn == 'topk-softmax':\n",
    "        attn_kwargs['attn_score_fn_params'] = dict(k=3, straight_through=True)\n",
    "    elif attn_fn == 'hard':\n",
    "        attn_kwargs['attn_score_fn_params'] = dict(straight_through=True)\n",
    "\n",
    "    # discrete_intermediate args\n",
    "    intermediate_discretization = dict(discrete_intermediate=(disc_map is not None))\n",
    "    if disc_map is not None:\n",
    "        intermediate_discretization['discretize_map'] = disc_map\n",
    "    match disc_map:\n",
    "        case 'gumbel-softmax':\n",
    "            intermediate_discretization['discretization_map_params'] = dict(tau=1, hard=False)\n",
    "        case 'hard':\n",
    "            intermediate_discretization['discretization_map_params'] = dict(straight_through=True)\n",
    "        case 'topk-softmax':\n",
    "            intermediate_discretization['discretization_map_params'] = dict(k=3, straight_through=True)\n",
    "\n",
    "    job_model_config.update(dict(\n",
    "        n_layers=L, d_model=D, dff=D*F,\n",
    "        pos_enc_type=posenc,\n",
    "        input_recall=ir,\n",
    "        attn_kwargs=attn_kwargs,\n",
    "        intermediate_discretization=intermediate_discretization\n",
    "        ))\n",
    "\n",
    "    # ----------------------------\n",
    "\n",
    "    ### Train config\n",
    "    job_train_config.update(dict(\n",
    "        progressive_training=progtr,\n",
    "        incremental_training=inctr\n",
    "    ))\n",
    "\n",
    "    # ----------------------------\n",
    "\n",
    "    ### Data config\n",
    "    job_data_config.update(dict(\n",
    "        train_random_sequence_length=randlen,\n",
    "    ))\n",
    "\n",
    "    if inctr and not progtr:\n",
    "        continue\n",
    "\n",
    "    job_config = dict(model_config=job_model_config, train_config=job_train_config, data_config=job_data_config)\n",
    "    job_config = AttributeDict(job_config)\n",
    "    jobs_overwrite_params.append(job_config)\n",
    "\n",
    "print(f\"Generated {len(jobs_overwrite_params)} jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_job_config(config_upate, out_dir):\n",
    "    global base_model_config, base_train_config, base_data_config\n",
    "    model_config, train_config, data_config = tuple(copy.deepcopy(c) for c in (base_model_config, base_train_config, base_data_config))\n",
    "\n",
    "    model_config.update(config_upate.get('model_config', {}))\n",
    "    train_config.update(config_upate.get('train_config', {}))\n",
    "    data_config.update(config_upate.get('data_config', {}))\n",
    "\n",
    "    experiment_name, _ = get_experiment_name(model_config, data_config, train_config)\n",
    "    experiment_name = experiment_name.replace(' ', '')\n",
    "\n",
    "    mkdir(os.path.join(out_dir, experiment_name))\n",
    "\n",
    "    with open(os.path.join(out_dir, f'{experiment_name}/model_config.yaml'), 'w') as f:\n",
    "        yaml.dump(model_config.todict(), f)\n",
    "\n",
    "    with open(os.path.join(out_dir, f'{experiment_name}/train_config.yaml'), 'w') as f:\n",
    "        yaml.dump(train_config.todict(), f)\n",
    "\n",
    "    with open(os.path.join(out_dir, f'{experiment_name}/data_config.yaml'), 'w') as f:\n",
    "        yaml.dump(data_config.todict(), f)\n",
    "\n",
    "    return model_config, train_config, data_config, experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_job_script(experiment_name):\n",
    "    filename = f'{job_directory}/{experiment_name}.job'\n",
    "    with open(filename, 'w') as fh:\n",
    "        fh.writelines(f\"#!/bin/bash\\n\")\n",
    "        fh.writelines(f\"#SBATCH --partition={partition}\\n\")\n",
    "        fh.writelines(f\"#SBATCH --job-name={experiment_name}\\n\")\n",
    "        fh.writelines(f\"#SBATCH --output={out_dir}/%j-{experiment_name}.out\\n\")\n",
    "        fh.writelines(f\"#SBATCH --ntasks={ntasks} --nodes={nodes}\\n\")\n",
    "        fh.writelines(f\"#SBATCH --cpus-per-gpu={cpu_per_gpu}\\n\")\n",
    "        fh.writelines(f\"#SBATCH --mem-per-cpu={mem_per_cpu}G\\n\")\n",
    "        fh.writelines(f\"#SBATCH --time={time_str}\\n\")\n",
    "        fh.writelines(f\"#SBATCH --mail-type=ALL\\n\")\n",
    "        fh.writelines(f\"#SBATCH --gpus={n_gpus}\\n\")\n",
    "        # fh.writelines(f\"#SBATCH --constraint={gpus_constraints}\\n\")\n",
    "\n",
    "        fh.writelines('\\n')\n",
    "        fh.writelines('module load StdEnv\\n')\n",
    "        fh.writelines('export SLURM_EXPORT_ENV=ALL\\n')\n",
    "        fh.writelines('\\n')\n",
    "\n",
    "        if cluster == 'grace':\n",
    "            fh.writelines(f\"module restore python_env\\n\") # load modules i need\n",
    "        elif cluster == 'misha':\n",
    "            fh.writelines(f\"module load miniconda\\n\") # load modules i need\n",
    "        else:\n",
    "            raise ValueError(f\"Cluster {cluster} not supported\")\n",
    "\n",
    "        # fh.writelines(f\"conda init\\n\")\n",
    "        fh.writelines(f\"conda activate neural_prog\\n\") # activate conda environment\n",
    "        fh.writelines(f\"conda info --envs\\n\") # activate conda environment\n",
    "\n",
    "        fh.writelines('\\n')\n",
    "        fh.writelines(f\"nvidia-smi -L\\n\") # print gpu information\n",
    "        fh.writelines('\\n')\n",
    "\n",
    "        fh.writelines(f\"cd {project_dir}\\n\") # navigate to project directory\n",
    "        fh.writelines('\\n')\n",
    "\n",
    "        # run python script\n",
    "        fh.writelines(f\"srun python train_recurrent.py --config_dir experiment_configs/{experiment_name}\\n\") # run python script\n",
    "\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-topk-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-topk-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-hard-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-hard-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-hard--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-hard--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-gumbel-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRTrue_discinterm-gumbel-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-topk-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-topk-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-hard-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-hard-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-hard--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-hard--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-gumbel-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_sinusoidal_IRFalse_discinterm-gumbel-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-topk-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-topk-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-hard-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-hard-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-hard--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-hard--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-gumbel-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRTrue_discinterm-gumbel-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-topk-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-topk-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-hard-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-hard-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-hard--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-hard--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-gumbel-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_rotary_IRFalse_discinterm-gumbel-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-topk-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-topk-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-hard-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-hard-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-hard--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-hard--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-gumbel-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRTrue_discinterm-gumbel-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-topk-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-topk-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-hard-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-hard-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-hard--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-hard--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-gumbel-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_t5_IRFalse_discinterm-gumbel-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-topk-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-topk-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-hard-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-hard-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-hard--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-hard--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-gumbel-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRTrue_discinterm-gumbel-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-topk-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-topk-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-topk-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-topk-softmax--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-hard-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-hard-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-hard-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-hard--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-hard--MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-gumbel-softmax-progressive_incremental-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-gumbel-softmax-progressive-MaxVal64-TrainLen16\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-gumbel-softmax--MaxVal64-TrainLen16RandLen\n",
      "Experiment Name: L2H4D256_alibi_IRFalse_discinterm-gumbel-softmax--MaxVal64-TrainLen16\n"
     ]
    }
   ],
   "source": [
    "job_script_files = []\n",
    "\n",
    "for job_params in jobs_overwrite_params:\n",
    "    base_model_config, base_train_config, base_data_config, experiment_name = create_job_config(job_params, config_out_dir)\n",
    "\n",
    "    print(f\"Experiment Name: {experiment_name}\")\n",
    "\n",
    "    job_script = create_job_script(experiment_name)\n",
    "    job_script_files.append(job_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0\n",
      "Submitted batch job 118141\n",
      "Submitted batch job 118142\n",
      "Submitted batch job 118143\n",
      "Submitted batch job 118144\n",
      "Submitted batch job 118145\n",
      "Submitted batch job 118146\n",
      "Submitted batch job 118147\n",
      "Submitted batch job 118148\n",
      "Submitted batch job 118149\n",
      "Submitted batch job 118150\n",
      "Submitted batch job 118151\n",
      "Submitted batch job 118152\n",
      "Submitted batch job 118153\n",
      "Submitted batch job 118154\n",
      "Submitted batch job 118155\n",
      "Submitted batch job 118156\n",
      "Submitted batch job 118157\n",
      "Submitted batch job 118158\n",
      "Submitted batch job 118159\n",
      "Submitted batch job 118160\n",
      "Submitted batch job 118161\n",
      "Submitted batch job 118162\n",
      "Submitted batch job 118163\n",
      "Submitted batch job 118164\n",
      "Submitted batch job 118165\n",
      "Submitted batch job 118166\n",
      "Submitted batch job 118167\n",
      "Submitted batch job 118168\n",
      "Submitted batch job 118169\n",
      "Submitted batch job 118170\n",
      "Submitted batch job 118171\n",
      "Submitted batch job 118172\n",
      "Submitted batch job 118173\n",
      "Submitted batch job 118174\n",
      "Submitted batch job 118175\n",
      "Submitted batch job 118176\n",
      "Submitted batch job 118177\n",
      "Submitted batch job 118178\n",
      "Submitted batch job 118179\n",
      "Submitted batch job 118180\n",
      "Submitted batch job 118181\n",
      "Submitted batch job 118182\n",
      "Submitted batch job 118183\n",
      "Submitted batch job 118184\n",
      "Submitted batch job 118185\n",
      "Submitted batch job 118186\n",
      "Submitted batch job 118187\n",
      "Submitted batch job 118188\n",
      "Submitted batch job 118189\n",
      "Submitted batch job 118190\n",
      "Submitted batch job 118191\n",
      "Submitted batch job 118192\n",
      "Submitted batch job 118193\n",
      "Submitted batch job 118194\n",
      "Submitted batch job 118195\n",
      "Submitted batch job 118196\n",
      "Submitted batch job 118197\n",
      "Submitted batch job 118198\n",
      "Submitted batch job 118199\n",
      "Submitted batch job 118200\n",
      "Submitted batch job 118201\n",
      "Submitted batch job 118202\n",
      "Submitted batch job 118203\n",
      "Submitted batch job 118204\n",
      "Submitted batch job 118205\n",
      "Submitted batch job 118206\n",
      "Submitted batch job 118207\n",
      "Submitted batch job 118208\n",
      "Submitted batch job 118209\n",
      "Submitted batch job 118210\n",
      "Submitted batch job 118211\n",
      "Submitted batch job 118212\n",
      "Submitted batch job 118213\n",
      "Submitted batch job 118214\n",
      "Submitted batch job 118215\n",
      "Submitted batch job 118216\n",
      "Submitted batch job 118217\n",
      "Submitted batch job 118218\n",
      "Submitted batch job 118219\n",
      "Submitted batch job 118220\n",
      "Submitted batch job 118221\n",
      "Submitted batch job 118222\n",
      "Submitted batch job 118223\n",
      "Submitted batch job 118224\n",
      "Submitted batch job 118225\n",
      "Submitted batch job 118226\n",
      "Submitted batch job 118227\n",
      "Submitted batch job 118228\n",
      "Submitted batch job 118229\n",
      "Submitted batch job 118230\n",
      "Submitted batch job 118231\n",
      "Submitted batch job 118232\n",
      "Submitted batch job 118233\n",
      "Submitted batch job 118234\n",
      "Submitted batch job 118235\n",
      "Submitted batch job 118236\n",
      "Submitted batch job 118237\n",
      "Submitted batch job 118238\n",
      "Submitted batch job 118239\n",
      "Submitted batch job 118240\n",
      "Submitted batch job 118241\n",
      "Submitted batch job 118242\n",
      "Submitted batch job 118243\n",
      "Submitted batch job 118244\n",
      "Submitted batch job 118245\n",
      "Submitted batch job 118246\n",
      "Submitted batch job 118247\n",
      "Submitted batch job 118248\n",
      "Submitted batch job 118249\n",
      "Submitted batch job 118250\n",
      "Submitted batch job 118251\n",
      "Submitted batch job 118252\n",
      "Submitted batch job 118253\n",
      "Submitted batch job 118254\n",
      "Submitted batch job 118255\n",
      "Submitted batch job 118256\n",
      "Submitted batch job 118257\n",
      "Submitted batch job 118258\n",
      "Submitted batch job 118259\n",
      "Submitted batch job 118260\n",
      "Submitted batch job 118261\n",
      "Submitted batch job 118262\n",
      "Submitted batch job 118263\n",
      "Submitted batch job 118264\n",
      "Submitted batch job 118265\n",
      "Submitted batch job 118266\n",
      "Submitted batch job 118267\n",
      "Submitted batch job 118268\n",
      "Submitted batch job 118269\n",
      "Submitted batch job 118270\n",
      "Submitted batch job 118271\n",
      "Submitted batch job 118272\n",
      "Submitted batch job 118273\n",
      "Submitted batch job 118274\n",
      "Submitted batch job 118275\n",
      "Submitted batch job 118276\n",
      "Submitted batch job 118277\n",
      "Submitted batch job 118278\n",
      "Submitted batch job 118279\n",
      "Submitted batch job 118280\n",
      "Submitted batch job 118281\n",
      "Submitted batch job 118282\n",
      "Submitted batch job 118283\n",
      "Submitted batch job 118284\n",
      "Submitted batch job 118285\n",
      "Submitted batch job 118286\n",
      "Submitted batch job 118287\n",
      "Submitted batch job 118288\n",
      "Submitted batch job 118289\n",
      "Submitted batch job 118290\n",
      "Submitted batch job 118291\n",
      "Submitted batch job 118292\n",
      "Submitted batch job 118293\n",
      "Submitted batch job 118294\n",
      "Submitted batch job 118295\n",
      "Submitted batch job 118296\n",
      "Submitted batch job 118297\n",
      "Submitted batch job 118298\n",
      "Submitted batch job 118299\n",
      "Submitted batch job 118300\n",
      "Submitted batch job 118301\n",
      "Submitted batch job 118302\n",
      "Submitted batch job 118303\n",
      "Submitted batch job 118304\n",
      "Submitted batch job 118305\n",
      "Submitted batch job 118306\n",
      "Submitted batch job 118307\n",
      "Submitted batch job 118308\n",
      "Submitted batch job 118309\n",
      "Submitted batch job 118310\n",
      "Submitted batch job 118311\n",
      "Submitted batch job 118312\n",
      "Submitted batch job 118313\n",
      "Submitted batch job 118314\n",
      "Submitted batch job 118315\n",
      "Submitted batch job 118316\n",
      "Submitted batch job 118317\n",
      "Submitted batch job 118318\n",
      "Submitted batch job 118319\n",
      "Submitted batch job 118320\n",
      "Submitted batch job 118321\n",
      "Submitted batch job 118322\n",
      "Submitted batch job 118323\n",
      "Submitted batch job 118324\n",
      "Submitted batch job 118325\n",
      "Submitted batch job 118326\n",
      "Submitted batch job 118327\n",
      "Submitted batch job 118328\n",
      "Submitted batch job 118329\n",
      "Submitted batch job 118330\n",
      "Submitted batch job 118331\n",
      "Submitted batch job 118332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_trials = 1\n",
    "\n",
    "confirm = input(\"Do you want to submit the jobs? (y/n): \")\n",
    "\n",
    "if confirm == 'y':\n",
    "    for ir in range(n_trials):\n",
    "        print('Trial:', ir)\n",
    "        for job_script in job_script_files:\n",
    "            os.system(f'sbatch \"{job_script}\"')\n",
    "        print()\n",
    "else:\n",
    "    print(\"Not submitting jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
