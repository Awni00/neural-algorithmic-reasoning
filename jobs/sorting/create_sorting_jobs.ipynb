{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from dotenv import load_dotenv\n",
    "import copy\n",
    "import yaml\n",
    "\n",
    "import os, sys; sys.path.insert(0, os.path.abspath('../..')) # add project root dir to path\n",
    "from experiments.sorting.model import get_experiment_name\n",
    "from models.utils import AttributeDict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def mkdir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global job parameters\n",
    "\n",
    "job_directory = f\"job_scripts\"\n",
    "out_dir = f'.out'\n",
    "time_str = '00-4:00:00'\n",
    "partition = 'gpu'\n",
    "ntasks = 1\n",
    "nodes = 1\n",
    "cpu_per_gpu = 8\n",
    "mem_per_cpu = 64\n",
    "n_gpus = 1\n",
    "\n",
    "# gpus_constraints = '\"a100|rtx3090|v100|rtx2080ti\"' # for grace\n",
    "# gpus_constraints = \"a40\" #'\"h100|a100\"' # for misha\n",
    "\n",
    "netid = os.getenv('NETID')\n",
    "project_dir = f\"/home/{netid}/project/neural-algorithmic-reasoning/experiments/sorting\"\n",
    "\n",
    "mkdir(job_directory)\n",
    "mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base model, train, and data config\n",
    "import yaml\n",
    "base_config_dir = f'{project_dir}/experiment_configs/base_config'\n",
    "\n",
    "with open(os.path.join(base_config_dir, 'model_config.yaml')) as f:\n",
    "    base_model_config = AttributeDict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "\n",
    "with open(os.path.join(base_config_dir, 'train_config.yaml')) as f:\n",
    "    base_train_config = AttributeDict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "\n",
    "with open(os.path.join(base_config_dir, 'data_config.yaml')) as f:\n",
    "    base_data_config = AttributeDict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "\n",
    "config_out_dir = f'{project_dir}/experiment_configs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 32 jobs\n"
     ]
    }
   ],
   "source": [
    "n_layers = [2, 4]\n",
    "d_model = [256]\n",
    "F = [2]\n",
    "pos_enc_type = ['sinusoidal', 'rotary', 't5', 'alibi']\n",
    "input_recall = [True, False]\n",
    "# attn_score_fn = ['softmax', 'topk-softmax', 'hard', 'sigmoid']\n",
    "attn_score_fn = ['topk-softmax', 'hard']\n",
    "\n",
    "jobs_overwrite_params = []\n",
    "for L, D, F, posenc, ir, attn_fn in itertools.product(n_layers, d_model, F, pos_enc_type, input_recall, attn_score_fn):\n",
    "    # copy base configs\n",
    "    job_model_config = copy.deepcopy(base_model_config)\n",
    "    job_train_config = copy.deepcopy(base_train_config)\n",
    "    job_data_config = copy.deepcopy(base_data_config)\n",
    "\n",
    "    # update model config\n",
    "    attn_kwargs = dict(attn_score_fn=attn_fn)\n",
    "    if attn_fn == 'topk-softmax':\n",
    "        attn_kwargs['attn_score_fn_params'] = dict(k=3, straight_through=True)\n",
    "    elif attn_fn == 'hard':\n",
    "        attn_kwargs['attn_score_fn_params'] = dict(straight_through=True)\n",
    "\n",
    "    job_model_config.update(dict(n_layers=L, d_model=D, dff=D*F, pos_enc_type=posenc, input_recall=ir, attn_kwargs=attn_kwargs))\n",
    "\n",
    "    job_config = dict(model_config=job_model_config, train_config=job_train_config, data_config=job_data_config)\n",
    "    job_config = AttributeDict(job_config)\n",
    "    jobs_overwrite_params.append(job_config)\n",
    "\n",
    "print(f\"Generated {len(jobs_overwrite_params)} jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_job_config(config_upate, out_dir):\n",
    "    global base_model_config, base_train_config, base_data_config\n",
    "    model_config, train_config, data_config = tuple(copy.deepcopy(c) for c in (base_model_config, base_train_config, base_data_config))\n",
    "\n",
    "    model_config.update(config_upate.get('model_config', {}))\n",
    "    train_config.update(config_upate.get('train_config', {}))\n",
    "    data_config.update(config_upate.get('data_config', {}))\n",
    "\n",
    "    experiment_name, _ = get_experiment_name(model_config, data_config, train_config)\n",
    "    experiment_name = experiment_name.replace(' ', '')\n",
    "\n",
    "    mkdir(os.path.join(out_dir, experiment_name))\n",
    "\n",
    "    with open(os.path.join(out_dir, f'{experiment_name}/model_config.yaml'), 'w') as f:\n",
    "        yaml.dump(model_config.todict(), f)\n",
    "\n",
    "    with open(os.path.join(out_dir, f'{experiment_name}/train_config.yaml'), 'w') as f:\n",
    "        yaml.dump(train_config.todict(), f)\n",
    "\n",
    "    with open(os.path.join(out_dir, f'{experiment_name}/data_config.yaml'), 'w') as f:\n",
    "        yaml.dump(data_config.todict(), f)\n",
    "\n",
    "    return model_config, train_config, data_config, experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_job_script(experiment_name):\n",
    "    filename = f'{job_directory}/{experiment_name}.job'\n",
    "    with open(filename, 'w') as fh:\n",
    "        fh.writelines(f\"#!/bin/bash\\n\")\n",
    "        fh.writelines(f\"#SBATCH --partition={partition}\\n\")\n",
    "        fh.writelines(f\"#SBATCH --job-name={experiment_name}\\n\")\n",
    "        fh.writelines(f\"#SBATCH --output={out_dir}/%j-{experiment_name}.out\\n\")\n",
    "        fh.writelines(f\"#SBATCH --ntasks={ntasks} --nodes={nodes}\\n\")\n",
    "        fh.writelines(f\"#SBATCH --cpus-per-gpu={cpu_per_gpu}\\n\")\n",
    "        fh.writelines(f\"#SBATCH --mem-per-cpu={mem_per_cpu}G\\n\")\n",
    "        fh.writelines(f\"#SBATCH --time={time_str}\\n\")\n",
    "        fh.writelines(f\"#SBATCH --mail-type=ALL\\n\")\n",
    "        fh.writelines(f\"#SBATCH --gpus={n_gpus}\\n\")\n",
    "        # fh.writelines(f\"#SBATCH --constraint={gpus_constraints}\\n\")\n",
    "\n",
    "        fh.writelines('\\n')\n",
    "        fh.writelines('module load StdEnv\\n')\n",
    "        fh.writelines('export SLURM_EXPORT_ENV=ALL\\n')\n",
    "        fh.writelines('\\n')\n",
    "\n",
    "        # fh.writelines(f\"module restore python_env\\n\") # load modules i need\n",
    "        fh.writelines(f\"module load miniconda\\n\") # load modules i need\n",
    "        # fh.writelines(f\"conda init\\n\")\n",
    "        fh.writelines(f\"conda activate neural_prog\\n\") # activate conda environment\n",
    "        fh.writelines(f\"conda info --envs\\n\") # activate conda environment\n",
    "\n",
    "        fh.writelines('\\n')\n",
    "        fh.writelines(f\"nvidia-smi -L\\n\") # print gpu information\n",
    "        fh.writelines('\\n')\n",
    "\n",
    "        fh.writelines(f\"cd {project_dir}\\n\") # navigate to project directory\n",
    "        fh.writelines('\\n')\n",
    "\n",
    "        # run python script\n",
    "        fh.writelines(f\"srun python train.py --config_dir experiment_configs/{experiment_name}\\n\") # run python script\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_sinusoidal_IRTrue_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_sinusoidal_IRTrue_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_sinusoidal_IRFalse_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_sinusoidal_IRFalse_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_rotary_IRTrue_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_rotary_IRTrue_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_rotary_IRFalse_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_rotary_IRFalse_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_t5_IRTrue_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_t5_IRTrue_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_t5_IRFalse_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_t5_IRFalse_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_alibi_IRTrue_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_alibi_IRTrue_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_alibi_IRFalse_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L2H4D256_alibi_IRFalse_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_sinusoidal_IRTrue_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_sinusoidal_IRTrue_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_sinusoidal_IRFalse_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_sinusoidal_IRFalse_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_rotary_IRTrue_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_rotary_IRTrue_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_rotary_IRFalse_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_rotary_IRFalse_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_t5_IRTrue_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_t5_IRTrue_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_t5_IRFalse_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_t5_IRFalse_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_alibi_IRTrue_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_alibi_IRTrue_hard-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_alibi_IRFalse_topk-softmax-ST\n",
      "Experiment Name: MaxVal64-TrainLen16-L4H4D256_alibi_IRFalse_hard-ST\n"
     ]
    }
   ],
   "source": [
    "job_script_files = []\n",
    "\n",
    "for job_params in jobs_overwrite_params:\n",
    "    base_model_config, base_train_config, base_data_config, experiment_name = create_job_config(job_params, config_out_dir)\n",
    "\n",
    "    print(f\"Experiment Name: {experiment_name}\")\n",
    "\n",
    "    job_script = create_job_script(experiment_name)\n",
    "    job_script_files.append(job_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0\n",
      "Submitted batch job 82075\n",
      "Submitted batch job 82076\n",
      "Submitted batch job 82077\n",
      "Submitted batch job 82078\n",
      "Submitted batch job 82079\n",
      "Submitted batch job 82080\n",
      "Submitted batch job 82081\n",
      "Submitted batch job 82082\n",
      "Submitted batch job 82083\n",
      "Submitted batch job 82084\n",
      "Submitted batch job 82085\n",
      "Submitted batch job 82086\n",
      "Submitted batch job 82087\n",
      "Submitted batch job 82088\n",
      "Submitted batch job 82089\n",
      "Submitted batch job 82090\n",
      "Submitted batch job 82091\n",
      "Submitted batch job 82092\n",
      "Submitted batch job 82093\n",
      "Submitted batch job 82094\n",
      "Submitted batch job 82095\n",
      "Submitted batch job 82096\n",
      "Submitted batch job 82097\n",
      "Submitted batch job 82098\n",
      "Submitted batch job 82099\n",
      "Submitted batch job 82100\n",
      "Submitted batch job 82101\n",
      "Submitted batch job 82102\n",
      "Submitted batch job 82103\n",
      "Submitted batch job 82104\n",
      "Submitted batch job 82105\n",
      "Submitted batch job 82106\n",
      "\n",
      "Trial: 1\n",
      "Submitted batch job 82107\n",
      "Submitted batch job 82108\n",
      "Submitted batch job 82109\n",
      "Submitted batch job 82110\n",
      "Submitted batch job 82111\n",
      "Submitted batch job 82112\n",
      "Submitted batch job 82113\n",
      "Submitted batch job 82114\n",
      "Submitted batch job 82115\n",
      "Submitted batch job 82116\n",
      "Submitted batch job 82117\n",
      "Submitted batch job 82118\n",
      "Submitted batch job 82119\n",
      "Submitted batch job 82120\n",
      "Submitted batch job 82121\n",
      "Submitted batch job 82122\n",
      "Submitted batch job 82123\n",
      "Submitted batch job 82124\n",
      "Submitted batch job 82125\n",
      "Submitted batch job 82126\n",
      "Submitted batch job 82127\n",
      "Submitted batch job 82128\n",
      "Submitted batch job 82129\n",
      "Submitted batch job 82130\n",
      "Submitted batch job 82131\n",
      "Submitted batch job 82132\n",
      "Submitted batch job 82133\n",
      "Submitted batch job 82134\n",
      "Submitted batch job 82135\n",
      "Submitted batch job 82136\n",
      "Submitted batch job 82137\n",
      "Submitted batch job 82138\n",
      "\n",
      "Trial: 2\n",
      "Submitted batch job 82139\n",
      "Submitted batch job 82140\n",
      "Submitted batch job 82141\n",
      "Submitted batch job 82142\n",
      "Submitted batch job 82143\n",
      "Submitted batch job 82144\n",
      "Submitted batch job 82145\n",
      "Submitted batch job 82146\n",
      "Submitted batch job 82147\n",
      "Submitted batch job 82148\n",
      "Submitted batch job 82149\n",
      "Submitted batch job 82150\n",
      "Submitted batch job 82151\n",
      "Submitted batch job 82152\n",
      "Submitted batch job 82153\n",
      "Submitted batch job 82154\n",
      "Submitted batch job 82155\n",
      "Submitted batch job 82156\n",
      "Submitted batch job 82157\n",
      "Submitted batch job 82158\n",
      "Submitted batch job 82159\n",
      "Submitted batch job 82160\n",
      "Submitted batch job 82161\n",
      "Submitted batch job 82162\n",
      "Submitted batch job 82163\n",
      "Submitted batch job 82164\n",
      "Submitted batch job 82165\n",
      "Submitted batch job 82166\n",
      "Submitted batch job 82167\n",
      "Submitted batch job 82168\n",
      "Submitted batch job 82169\n",
      "Submitted batch job 82170\n",
      "\n",
      "Trial: 3\n",
      "Submitted batch job 82171\n",
      "Submitted batch job 82172\n",
      "Submitted batch job 82173\n",
      "Submitted batch job 82174\n",
      "Submitted batch job 82175\n",
      "Submitted batch job 82176\n",
      "Submitted batch job 82177\n",
      "Submitted batch job 82178\n",
      "Submitted batch job 82179\n",
      "Submitted batch job 82180\n",
      "Submitted batch job 82181\n",
      "Submitted batch job 82182\n",
      "Submitted batch job 82183\n",
      "Submitted batch job 82184\n",
      "Submitted batch job 82185\n",
      "Submitted batch job 82186\n",
      "Submitted batch job 82187\n",
      "Submitted batch job 82188\n",
      "Submitted batch job 82189\n",
      "Submitted batch job 82190\n",
      "Submitted batch job 82191\n",
      "Submitted batch job 82192\n",
      "Submitted batch job 82193\n",
      "Submitted batch job 82194\n",
      "Submitted batch job 82195\n",
      "Submitted batch job 82196\n",
      "Submitted batch job 82197\n",
      "Submitted batch job 82198\n",
      "Submitted batch job 82199\n",
      "Submitted batch job 82200\n",
      "Submitted batch job 82201\n",
      "Submitted batch job 82202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_trials = 4\n",
    "\n",
    "confirm = input(\"Do you want to submit the jobs? (y/n): \")\n",
    "\n",
    "if confirm == 'y':\n",
    "    for ir in range(n_trials):\n",
    "        print('Trial:', ir)\n",
    "        for job_script in job_script_files:\n",
    "            os.system(f'sbatch \"{job_script}\"')\n",
    "        print()\n",
    "else:\n",
    "    print(\"Not submitting jobs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
